#!/usr/bin/env python3
"""
ğŸš€ í†µí•© í”„ë¡œì íŠ¸ ë„êµ¬ (Unified Project Tool) v2.0
- ì½”ë“œ/JSON ê²€ì¦
- ë©”íƒ€ë°ì´í„° ë° ë¬¸ì„œ ìƒì„±
- ìš©ì–´ì§‘ ë¶„ì„
- CLI ì„œë¸Œì»¤ë§¨ë“œ ì§€ì›

Usage:
  python3 tools/project_tool.py           # ì „ì²´ ê²€ì¦ (ê¸°ë³¸)
  python3 tools/project_tool.py validate  # ê²€ì¦ë§Œ
  python3 tools/project_tool.py build     # ë¹Œë“œë§Œ
  python3 tools/project_tool.py glossary  # ìš©ì–´ì§‘ ë¶„ì„
  python3 tools/project_tool.py stats     # í†µê³„ ì¶œë ¥
"""

from __future__ import annotations
import json
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Any
from collections import defaultdict

# ============================================================================
# ì„¤ì • ë° ê²½ë¡œ
# ============================================================================

PROJECT_ROOT = Path(__file__).parent.parent.resolve()
SCRIPTS_DIR = PROJECT_ROOT / "Scripts"
LOCALIZATION_DIR = PROJECT_ROOT / "LOCALIZATION"
DOCS_DIR = PROJECT_ROOT / "Docs"
TOOLS_DIR = PROJECT_ROOT / "tools"
ASSETS_DIR = PROJECT_ROOT / "Assets"

# ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ (í•œ ë²ˆë§Œ ì»´íŒŒì¼)
FUNC_PATTERN = re.compile(r'(?:public|private|protected|internal)\s+(?:static\s+)?(?:\w+\s+)?(\w+)\s*\(')
CLASS_PATTERN = re.compile(r'(?:public|internal|private)\s+(?:static\s+)?(?:partial\s+)?class\s+(\w+)')
NAMESPACE_PATTERN = re.compile(r'namespace\s+([\w\.]+)')
METHOD_PATTERN = re.compile(r'public\s+(?:static\s+)?([\w\[\]<>]+)\s+(\w+)\s*\(([^)]*)\)')
CLASSIFICATION_PATTERN = re.compile(r'\* ë¶„ë¥˜:\s*\[([^\]]+)\]')
ROLE_PATTERN = re.compile(r'\* ì—­í• :\s*([^\n\*]+)')


# Harmony í•¨ìˆ˜ëª… (ì¤‘ë³µ í—ˆìš©)
HARMONY_FUNCS = frozenset({"Postfix", "Prefix", "TargetMethod"})


def _read_file(path: Path) -> str | None:
    """íŒŒì¼ì„ ì½ê³  ë‚´ìš© ë°˜í™˜. ì‹¤íŒ¨ ì‹œ None. utf-8-sigë¡œ BOM ì²˜ë¦¬."""
    try:
        return path.read_text(encoding='utf-8-sig')
    except IOError:
        return None

# Master Code Noise Regex
# 1. Line Comment: //...
# 2. Block Comment: /*...*/
# 3. Verbatim String: @"..." (allows "")
# 4. Normal String: "..." (allows \")
# 5. Char Literal: '.' (allows \')
NOISE_PATTERN = re.compile(
    r'//[^\n]*|/\*.*?\*/|@"(?:[^"]|"")*"|"(?:[^"\\]|\\.)*"|\'(?:[^\'\\]|\\.)*\'',
    re.DOTALL
)

def _strip_code_noise(content: str) -> str:
    """ì£¼ì„ ë° ë¬¸ìì—´ ì œê±°í•˜ì—¬ êµ¬ì¡°ë§Œ ì¶”ì¶œ (Master Regex ì‚¬ìš©)"""
    # ë§¤ì¹­ëœ ëª¨ë“  ë…¸ì´ì¦ˆ(ì£¼ì„, ë¬¸ìì—´)ë¥¼ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜í•˜ì—¬ ê¸¸ì´/ë¼ì¸ ë³´ì¡´
    # ë‹¤ë§Œ ë‹¨ìˆœíˆ ì œê±°('')í•˜ë©´ ì¸ë±ìŠ¤ê°€ ë°€ë¦´ ìˆ˜ ìˆìœ¼ë‚˜, 
    # ì¤‘ê´„í˜¸ ê°œìˆ˜ë§Œ ì„¸ëŠ” ìš©ë„ë¼ë©´ ì œê±°í•´ë„ ë¬´ë°©.
    return NOISE_PATTERN.sub('', content)


# ============================================================================
# 1. ì½”ë“œ ë° êµ¬ë¬¸ ê²€ì¦
# ============================================================================

def verify_code() -> bool:
    """C# ì½”ë“œ ì¤‘ë³µ ë° êµ¬ë¬¸ ì˜¤ë¥˜ ê²€ì¦"""
    print("\n" + "=" * 80)
    print("ğŸ” ì½”ë“œ ê²€ì¦ (Code Validation)")
    print("=" * 80)

    functions: dict[str, list[str]] = {}
    classes: dict[str, list[str]] = {}
    errors: list[str] = []
    missing_headers: list[str] = []

    for cs_file in SCRIPTS_DIR.rglob("*.cs"):
        if "_Legacy" in str(cs_file):
            continue

        content = _read_file(cs_file)
        if content is None:
            continue

        rel_path = str(cs_file.relative_to(PROJECT_ROOT))

        # í‘œì¤€ í—¤ë” ì²´í¬
        if "ë¶„ë¥˜:" not in content or "ì—­í• :" not in content:
            missing_headers.append(rel_path)

        # í•¨ìˆ˜/í´ë˜ìŠ¤ ì°¾ê¸°
        for func_name in FUNC_PATTERN.findall(content):
            functions.setdefault(func_name, []).append(rel_path)

        for class_name in CLASS_PATTERN.findall(content):
            classes.setdefault(class_name, []).append(rel_path)

        # êµ¬ë¬¸ ì˜¤ë¥˜ ì²´í¬
        clean = _strip_code_noise(content)
        open_count, close_count = clean.count('{'), clean.count('}')
        if open_count != close_count:
            errors.append(f"{rel_path}: ì¤‘ê´„í˜¸ ë¶ˆì¼ì¹˜ ({open_count} vs {close_count})")

    # ê²°ê³¼ ë³´ê³ 
    dupes = {}
    for name, paths in functions.items():
        if name in HARMONY_FUNCS:
            continue
        
        # ìœ ë‹ˆí¬í•œ íŒŒì¼ ê²½ë¡œë§Œ ì¹´ìš´íŠ¸ (ê°™ì€ íŒŒì¼ ë‚´ ì˜¤ë²„ë¡œë”© í—ˆìš©)
        unique_files = set(paths)
        if len(unique_files) > 1:
            dupes[name] = unique_files

    if dupes:
        print(f"âš ï¸  ì¤‘ë³µ í•¨ìˆ˜ íƒì§€: {len(dupes)}ê°œ (ì„œë¡œ ë‹¤ë¥¸ íŒŒì¼ì— ì¡´ì¬)")
        for name, files in list(dupes.items())[:5]:
            print(f"   - {name}: {len(files)}ê°œ íŒŒì¼")

    if errors:
        print(f"âŒ êµ¬ë¬¸ ì˜¤ë¥˜: {len(errors)}ê°œ")
        for e in errors:
            print(f"   - {e}")

    if missing_headers:
        print(f"âš ï¸  í‘œì¤€ í—¤ë” ëˆ„ë½: {len(missing_headers)}ê°œ íŒŒì¼")
        for h in missing_headers[:5]:
            print(f"   - {h}")

    passed = not errors and not missing_headers
    if not dupes and passed:
        print("âœ… ì½”ë“œ ê²€ì¦ í†µê³¼")
    
    return passed


# ============================================================================
# 2. ë²ˆì—­ ë°ì´í„° ê²€ì¦
# ============================================================================

def verify_localization() -> bool:
    """JSON ë²ˆì—­ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
    print("\n" + "=" * 80)
    print("ğŸ“š ë²ˆì—­ ë°ì´í„° ê²€ì¦ (Localization Validation)")
    print("=" * 80)

    total_entries = 0
    empty_count = 0
    dupe_count = 0

    def duplicate_key_checker(pairs):
        nonlocal dupe_count
        result = {}
        seen_keys = set()
        for key, value in pairs:
            if key in seen_keys:
                print(f"âš ï¸  ì¤‘ë³µ í‚¤ ë°œê²¬: {key}")
                dupe_count += 1
            else:
                seen_keys.add(key)
                result[key] = value
        return result

    for json_file in LOCALIZATION_DIR.rglob("*.json"):
        content = _read_file(json_file)
        if content is None:
            print(f"âŒ [{json_file.name}] íŒŒì¼ ì½ê¸° ì˜¤ë¥˜")
            return False

        try:
            # Custom loader to catch duplicates
            data = json.loads(content, object_pairs_hook=duplicate_key_checker)
            
            # 1. ë¹ˆ ê°’ ì²´í¬
            if isinstance(data, dict):
                 stack = [data]
                 while stack:
                     current = stack.pop()
                     if isinstance(current, dict):
                         # items() returns key, value
                         for k, v in current.items():
                             if isinstance(v, (dict, list)):
                                 stack.append(v)
                             elif isinstance(v, str):
                                 total_entries += 1
                                 if not v.strip():
                                     # print(f"âš ï¸  [{json_file.name}] ë¹ˆ ê°’: {k}")
                                     empty_count += 1
                     elif isinstance(current, list):
                         for item in current:
                             if isinstance(item, (dict, list)):
                                 stack.append(item)
                             elif isinstance(item, str):
                                 # List strings usually used for leveltext, not key-value
                                 pass

        except Exception as e:
            print(f"âŒ [{json_file.name}] ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜: {e}")
            return False

    print(f"ì´ ë²ˆì—­ í•­ëª©: {total_entries}ê°œ")
    if empty_count:
        print(f"âš ï¸  ë¹ˆ ë²ˆì—­ í•­ëª©: {empty_count}ê°œ")
    if dupe_count:
        print(f"âš ï¸  ì¤‘ë³µ í‚¤ ë°œê²¬: {dupe_count}ê°œ")

    if not empty_count and not dupe_count:
        print("âœ… ë²ˆì—­ ë°ì´í„° ë¬´ê²°ì„± í™•ì¸")

    return dupe_count == 0

# ============================================================================
# 2.5 ë¹Œë“œ ê²€ì¦ (Build Validation)
# ============================================================================

def verify_build() -> bool:
    """ë¹Œë“œ ê²€ì¦ (Qud ëª¨ë“œëŠ” .cs íŒŒì¼ ì§ì ‘ ë¡œë“œí•˜ë¯€ë¡œ ìŠ¤í‚µ)"""
    print("\n" + "=" * 80)
    print("ğŸ”¨ ë¹Œë“œ ê²€ì¦ (Build Validation)")
    print("=" * 80)

    # Caves of Qud ëª¨ë“œëŠ” .cs íŒŒì¼ì„ ê²Œì„ì—ì„œ ì§ì ‘ ì»´íŒŒì¼
    # csproj/dotnet build ë¶ˆí•„ìš”
    print("âœ… ë¹Œë“œ ì„±ê³µ (Qud ëª¨ë“œëŠ” .cs ì§ì ‘ ë¡œë“œ)")
    return True
# ============================================================================
# 3. ë©”íƒ€ë°ì´í„° ë° ì¸ë±ìŠ¤ ìƒì„±
# ============================================================================

def _scan_scripts() -> dict[str, dict[str, Any]]:
    """Scripts ë””ë ‰í† ë¦¬ ìŠ¤ìº”"""
    scripts: dict[str, dict[str, Any]] = {}
    
    for cs_file in SCRIPTS_DIR.rglob("*.cs"):
        if "_Legacy" in str(cs_file):
            continue
            
        content = _read_file(cs_file)
        if content is None:
            continue

        rel_path = str(cs_file.relative_to(PROJECT_ROOT))

        # í—¤ë” ì •ë³´ ì¶”ì¶œ
        cls_match = CLASSIFICATION_PATTERN.search(content)
        role_match = ROLE_PATTERN.search(content)
        ns_match = NAMESPACE_PATTERN.search(content)

        scripts[rel_path] = {
            "classification": cls_match.group(1).strip() if cls_match else "N/A",
            "role": role_match.group(1).strip() if role_match else "N/A",
            "namespace": ns_match.group(1) if ns_match else None,
            "classes": CLASS_PATTERN.findall(content),
            "methods": [
                {"name": m[1], "return": m[0], "params": m[2].strip() or ""}
                for m in METHOD_PATTERN.findall(content)
            ]
        }
    
    return scripts


def build_project_references() -> None:
    """í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„°(json) ë° ì¸ë±ìŠ¤(md) ìƒì„±"""
    print("\n" + "=" * 80)
    print("ğŸ”§ í”„ë¡œì íŠ¸ ë ˆí¼ëŸ°ìŠ¤ ìƒì„± (Metadata & Index)")
    print("=" * 80)

    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    db: dict[str, Any] = {
        "generated": timestamp,
        "scripts": _scan_scripts(),
        "tools": {},
        "docs": {},
        "localization": {}
    }

    # ë„êµ¬ ìŠ¤ìº”
    for path in TOOLS_DIR.iterdir():
        if path.is_file() and path.suffix == ".py":
            db["tools"][path.name] = {"type": "script", "size": path.stat().st_size}
        elif path.is_dir() and not path.name.startswith(('.', '_')):
            db["tools"][path.name] = {"type": "tool_folder"}

    # ë¬¸ì„œ ìŠ¤ìº”
    for md_file in DOCS_DIR.glob("*.md"):
        mtime = datetime.fromtimestamp(md_file.stat().st_mtime)
        db["docs"][md_file.name] = {"modified": mtime.strftime("%Y-%m-%d")}

    # ë¡œì»¬ë¼ì´ì œì´ì…˜ ìŠ¤ìº”
    for json_file in LOCALIZATION_DIR.rglob("*.json"):
        content = _read_file(json_file)
        if content is None:
            continue
        try:
            data = json.loads(content)
            db["localization"][json_file.name] = {
                "categories": list(data.keys()),
                "entries": sum(len(v) if isinstance(v, dict) else 0 for v in data.values())
            }
        except json.JSONDecodeError:
            pass

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    (TOOLS_DIR / "project_metadata.json").write_text(
        json.dumps(db, indent=2, ensure_ascii=False),
        encoding='utf-8'
    )

    # ì¸ë±ìŠ¤ ë¬¸ì„œ ìƒì„±
    _generate_project_index(db)
    _generate_quick_reference(db)

    print("âœ… ë©”íƒ€ë°ì´í„° ë° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (Docs 01, 02 ê°±ì‹ )")


def _generate_project_index(db: dict[str, Any]) -> None:
    """01_CORE_PROJECT_INDEX.md ìƒì„±"""
    lines = [
        "# ğŸ“š í”„ë¡œì íŠ¸ ì™„ì „ ì¸ë±ìŠ¤ (ìë™ ìƒì„±)",
        f"\n**ìƒì„±**: {db['generated']}\n",
        "ì´ ë¬¸ì„œëŠ” í”„ë¡œì íŠ¸ì˜ ëª¨ë“  íŒŒì¼ê³¼ ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. "
        "**ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ë§Œë“¤ê¸° ì „, ë°˜ë“œì‹œ ì—¬ê¸°ì„œ ê¸°ì¡´ ë©”ì„œë“œë¥¼ ê²€ìƒ‰í•˜ì‹­ì‹œì˜¤.**\n",
        "=" * 80
    ]

    # ë¶„ë¥˜ë³„ ê·¸ë£¹í™”
    by_class: dict[str, list[tuple[str, dict]]] = {}
    for key, meta in db["scripts"].items():
        cls = meta["classification"]
        by_class.setdefault(cls, []).append((key, meta))

    for cls in sorted(by_class.keys()):
        lines.append(f"\n## ğŸ“‚ [{cls}]")
        for key, meta in sorted(by_class[cls]):
            lines.append(f"\n### `{key}`")
            lines.append(f"- **ì—­í• **: {meta['role']}")
            if meta["namespace"]:
                lines.append(f"- **Namespace**: `{meta['namespace']}`")
            if meta["methods"]:
                lines.append("- **ê³µê°œ ë©”ì„œë“œ (Public Methods)**:")
                lines.append("  ```csharp")
                for m in meta["methods"][:15]:
                    lines.append(f"  {m['return']} {m['name']}({m['params']})")
                if len(meta["methods"]) > 15:
                    lines.append(f"  ... ì™¸ {len(meta['methods']) - 15}ê°œ")
                lines.append("  ```")

    (DOCS_DIR / "01_CORE_PROJECT_INDEX.md").write_text("\n".join(lines), encoding='utf-8')


def _generate_quick_reference(db: dict[str, Any]) -> None:
    """02_CORE_QUICK_REFERENCE.md ìƒì„±"""
    lines = [
        "# ğŸš€ í”„ë¡œì íŠ¸ ë¹ ë¥¸ ì°¸ì¡° (ìë™ ìƒì„±)",
        f"\n**ìƒì„±**: {db['generated']}\n",
        "## â­ í•µì‹¬ ê²½ë¡œ",
        "```",
        "Scripts/00_Core/00_00_01_TranslationEngine.cs  â†’ í•µì‹¬ ì—”ì§„",
        "Scripts/00_Core/00_00_03_LocalizationManager.cs â†’ ë°ì´í„° ê´€ë¦¬",
        "LOCALIZATION/**/*.json              â†’ ìš©ì–´ì§‘ ë°ì´í„°",
        "```",
        "\n## ğŸ“š ìš©ì–´ì§‘ í˜„í™©"
    ]

    for k, v in sorted(db["localization"].items()):
        lines.append(f"- `{k}`: {v['entries']}ê°œ í•­ëª©")

    lines.extend([
        "\n## â›” ì ˆëŒ€ ê¸ˆì§€ (DO NOT)",
        "```",
        "âŒ _Legacy/ í´ë”ì˜ ì½”ë“œ ì‚¬ìš©",
        "âŒ TranslationEngine ë¡œì§ ì¤‘ë³µ êµ¬í˜„",
        "âŒ ìƒ‰ìƒ íƒœê·¸/í”„ë¦¬í”½ìŠ¤ ìˆ˜ë™ ì²˜ë¦¬",
        "âŒ project_tool.py ê²€ì¦ ì—†ì´ ë°°í¬",
        "```",
        "\n## âœ… ì‘ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸",
        "```",
        "1. 01_CORE_PROJECT_INDEX.mdì—ì„œ ê¸°ì¡´ í•¨ìˆ˜ í™•ì¸",
        "2. Scripts/ ë‚´ë¶€ ë¡œì§ ìˆ˜ì •",
        "3. python3 tools/project_tool.py ë¡œ ê²€ì¦",
        "4. ./tools/deploy-mods.sh ë¡œ ê²Œì„ ì ìš©",
        "```"
    ])

    (DOCS_DIR / "02_CORE_QUICK_REFERENCE.md").write_text("\n".join(lines), encoding='utf-8')
    print("âœ… ë ˆí¼ëŸ°ìŠ¤ ê°€ì´ë“œ ê°±ì‹ : Docs/02_CORE_QUICK_REFERENCE.md")


# ============================================================================
# 4. ìš©ì–´ì§‘ ë¶„ì„ (Glossary Analysis) - analyze_glossary.py í†µí•©
# ============================================================================

def analyze_glossary() -> dict[str, Any]:
    """ìš©ì–´ì§‘ ì¤‘ë³µ ë° êµ¬ì¡° ë¶„ì„"""
    print("\n" + "=" * 80)
    print("ğŸ“Š ìš©ì–´ì§‘ ë¶„ì„ (Glossary Analysis)")
    print("=" * 80)

    # ëª¨ë“  JSON íŒŒì¼ ë¡œë“œ
    all_keys: dict[str, list[str]] = defaultdict(list)  # key -> [file:category, ...]
    stats = {"files": 0, "categories": 0, "entries": 0, "duplicates": 0}
    
    for json_file in sorted(LOCALIZATION_DIR.rglob("*.json")):
        if "_DEPRECATED" in str(json_file):
            continue
        content = _read_file(json_file)
        if content is None:
            continue
        try:
            data = json.loads(content)
            stats["files"] += 1
            rel_path = json_file.relative_to(LOCALIZATION_DIR)
            
            # êµ¬ì¡°í™”ëœ JSON (names, description_ko ë“±)
            if "names" in data:
                for eng_key in data.get("names", {}).keys():
                    all_keys[eng_key.lower()].append(f"{rel_path}")
                    stats["entries"] += 1
            # í‰ë©´ JSON (key: value)
            elif isinstance(data, dict):
                for category, entries in data.items():
                    if isinstance(entries, dict):
                        stats["categories"] += 1
                        for key in entries.keys():
                            all_keys[key.lower()].append(f"{rel_path}:{category}")
                            stats["entries"] += 1
        except json.JSONDecodeError:
            pass

    # ì¤‘ë³µ í‚¤ ì°¾ê¸°
    duplicates = {k: v for k, v in all_keys.items() if len(v) > 1}
    stats["duplicates"] = len(duplicates)

    print(f"ì´ JSON íŒŒì¼: {stats['files']}ê°œ")
    print(f"ì´ ì¹´í…Œê³ ë¦¬: {stats['categories']}ê°œ")
    print(f"ì´ ë²ˆì—­ í•­ëª©: {stats['entries']}ê°œ")

    if duplicates:
        print(f"\nâš ï¸  ì¤‘ë³µ í‚¤ ë°œê²¬: {len(duplicates)}ê°œ")
        for key, locations in list(duplicates.items())[:5]:
            print(f"   - '{key}': {', '.join(locations[:3])}")
    else:
        print("âœ… ì¤‘ë³µ í‚¤ ì—†ìŒ")

    return stats


# ============================================================================
# 5. í†µê³„ ì¶œë ¥ (Statistics)
# ============================================================================

def show_stats() -> None:
    """í”„ë¡œì íŠ¸ í†µê³„ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("ğŸ“ˆ í”„ë¡œì íŠ¸ í†µê³„ (Statistics)")
    print("=" * 80)

    # Scripts í†µê³„
    cs_files = list(SCRIPTS_DIR.rglob("*.cs"))
    cs_files = [f for f in cs_files if "_Legacy" not in str(f)]
    total_lines = 0
    for f in cs_files:
        content = _read_file(f)
        if content:
            total_lines += len(content.splitlines())

    print(f"\nğŸ“ Scripts:")
    print(f"   - C# íŒŒì¼: {len(cs_files)}ê°œ")
    print(f"   - ì´ ë¼ì¸: {total_lines:,}ì¤„")

    # Localization í†µê³„
    json_files = list(LOCALIZATION_DIR.rglob("*.json"))
    json_files = [f for f in json_files if "_DEPRECATED" not in str(f)]
    
    categories = {"CHARGEN": 0, "GAMEPLAY": 0, "UI": 0, "OBJECTS": 0}
    for f in json_files:
        rel = str(f.relative_to(LOCALIZATION_DIR))
        for cat in categories:
            if rel.startswith(cat):
                categories[cat] += 1
                break

    print(f"\nğŸ“š Localization:")
    print(f"   - JSON íŒŒì¼: {len(json_files)}ê°œ")
    for cat, count in categories.items():
        print(f"   - {cat}: {count}ê°œ")

    # Git í†µê³„
    try:
        result = subprocess.run(
            ["git", "rev-list", "--count", "HEAD"],
            cwd=PROJECT_ROOT, capture_output=True, text=True
        )
        commits = result.stdout.strip()
        print(f"\nğŸ“ Git: {commits} commits")
    except:
        pass


# ============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€ (CLI)
# ============================================================================

def print_usage():
    """ì‚¬ìš©ë²• ì¶œë ¥"""
    print("""
ğŸš€ Qud í•œê¸€í™” í”„ë¡œì íŠ¸ í†µí•© ë„êµ¬ v2.0

Usage:
  python3 tools/project_tool.py [command]

Commands:
  (none)    ì „ì²´ ê²€ì¦ ì‹¤í–‰ (ê¸°ë³¸)
  validate  ì½”ë“œ/JSON ê²€ì¦ë§Œ
  build     ë¹Œë“œë§Œ ì‹¤í–‰
  glossary  ìš©ì–´ì§‘ ë¶„ì„
  stats     í”„ë¡œì íŠ¸ í†µê³„
  help      ì´ ë„ì›€ë§ ì¶œë ¥
""")


def main() -> None:
    cmd = sys.argv[1] if len(sys.argv) > 1 else "all"

    if cmd == "help":
        print_usage()
        return

    if cmd == "stats":
        show_stats()
        return

    if cmd == "glossary":
        analyze_glossary()
        return

    print("\n" + "ğŸš€" * 40)
    print("  Qud í•œê¸€í™” í”„ë¡œì íŠ¸ í†µí•© ë„êµ¬ í™˜ê²½ ê²€ì¦ ì‹œì‘")
    print("ğŸš€" * 40)

    results = []

    if cmd in ("all", "validate"):
        results.append(verify_code())
        results.append(verify_localization())

    if cmd in ("all", "build"):
        results.append(verify_build())

    if cmd == "all":
        build_project_references()
        analyze_glossary()

    print("\n" + "=" * 80)
    if all(results):
        print("âœ¨ ëª¨ë“  ê²€ì¦ ë° ìƒì„± ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸  ì¼ë¶€ ê²€ì¦ ë‹¨ê³„ì—ì„œ ì£¼ì˜ì‚¬í•­ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()
