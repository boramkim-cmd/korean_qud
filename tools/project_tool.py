#!/usr/bin/env python3
"""
ğŸš€ í†µí•© í”„ë¡œì íŠ¸ ë„êµ¬ (Unified Project Tool)
- ì½”ë“œ/JSON ê²€ì¦
- ë©”íƒ€ë°ì´í„° ë° ë¬¸ì„œ ìƒì„±
- ë¯¸ë²ˆì—­ í•­ëª© íƒìƒ‰
"""

import os
import re
import json
from pathlib import Path
from datetime import datetime
from collections import OrderedDict

# ============================================================================
# ì„¤ì • ë° ê²½ë¡œ
# ============================================================================

# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.resolve()
SCRIPTS_DIR = PROJECT_ROOT / "Scripts"
LOCALIZATION_DIR = PROJECT_ROOT / "LOCALIZATION"
DOCS_DIR = PROJECT_ROOT / "Docs"
TOOLS_DIR = PROJECT_ROOT / "tools"
ASSETS_DIR = PROJECT_ROOT / "Assets"

# ============================================================================
# 1. ì½”ë“œ ë° êµ¬ë¬¸ ê²€ì¦
# ============================================================================

def verify_code():
    """C# ì½”ë“œ ì¤‘ë³µ ë° êµ¬ë¬¸ ì˜¤ë¥˜ ê²€ì¦"""
    print("\n" + "=" * 80)
    print("ğŸ” ì½”ë“œ ê²€ì¦ (Code Validation)")
    print("=" * 80)
    
    functions = {}
    classes = {}
    errors = []
    
    missing_headers = []
    
    for cs_file in SCRIPTS_DIR.rglob("*.cs"):
        if "_Legacy" in str(cs_file): continue
            
        with open(cs_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        rel_path = str(cs_file.relative_to(PROJECT_ROOT))
        
        # 0. í‘œì¤€ í—¤ë” ì²´í¬
        if "ë¶„ë¥˜:" not in content or "ì—­í• :" not in content:
            missing_headers.append(rel_path)

        # 1. í•¨ìˆ˜/í´ë˜ìŠ¤ ì°¾ê¸°
        func_pattern = r'(?:public|private|protected|internal)\s+(?:static\s+)?(?:\w+\s+)?(\w+)\s*\('
        for func_name in re.findall(func_pattern, content):
            if func_name not in functions: functions[func_name] = []
            functions[func_name].append(rel_path)
        
        class_pattern = r'(?:public|internal|private)\s+(?:static\s+)?(?:partial\s+)?class\s+(\w+)'
        for class_name in re.findall(class_pattern, content):
            if class_name not in classes: classes[class_name] = []
            classes[class_name].append(rel_path)
        
        # êµ¬ë¬¸ ì˜¤ë¥˜ ì²´í¬ (ì£¼ì„/ë¬¸ìì—´ ì œì™¸)
        clean = re.sub(r'//.*', '', content)
        clean = re.sub(r'/\*.*?\*/', '', clean, flags=re.DOTALL)
        clean = re.sub(r'"[^"\\]*(?:\\.[^"\\]*)*"', '', clean)
        clean = re.sub(r"'[^'\\]*(?:\\.[^'\\]*)*'", '', clean)
        
        if clean.count('{') != clean.count('}'):
            errors.append(f"{rel_path}: ì¤‘ê´„í˜¸ ë¶ˆì¼ì¹˜ ({clean.count('{')} vs {clean.count('}')})")
    
    # ë³´ê³ 
    dupes = {n: f for n, f in functions.items() if len(f) > 1 and n not in ["Postfix", "Prefix", "TargetMethod"]}
    if dupes:
        print(f"âš ï¸  ì¤‘ë³µ í•¨ìˆ˜ íƒì§€: {len(dupes)}ê°œ")
        for n, f in list(dupes.items())[:5]:
            print(f"   - {n}: {len(f)}ê°œ íŒŒì¼")
    
    if errors:
        print(f"âŒ êµ¬ë¬¸ ì˜¤ë¥˜: {len(errors)}ê°œ")
        for e in errors: print(f"   - {e}")
    
    if missing_headers:
        print(f"âš ï¸  í‘œì¤€ í—¤ë” ëˆ„ë½: {len(missing_headers)}ê°œ íŒŒì¼")
        for h in missing_headers[:5]:
            print(f"   - {h}")
    
    if not dupes and not errors and not missing_headers: print("âœ… ì½”ë“œ ê²€ì¦ í†µê³¼")
    return not errors and not missing_headers

# ============================================================================
# 2. ë²ˆì—­ ë°ì´í„° ê²€ì¦
# ============================================================================

def verify_localization():
    """JSON ë²ˆì—­ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
    print("\n" + "=" * 80)
    print("ğŸ“š ë²ˆì—­ ë°ì´í„° ê²€ì¦ (Localization Validation)")
    print("=" * 80)
    
    total_entries = 0
    empty_count = 0
    dupe_count = 0
    
    for json_file in LOCALIZATION_DIR.glob("*.json"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                content = f.read()
                data = json.loads(content)
            
            # 1. ë¹ˆ ê°’ ì²´í¬
            for cat, entries in data.items():
                if isinstance(entries, dict):
                    for k, v in entries.items():
                        total_entries += 1
                        if not v or not v.strip(): empty_count += 1
            
            # 2. ì¤‘ë³µ í‚¤ ì²´í¬
            cat_blocks = re.findall(r'"([^"]+)":\s*\{([^\}]*)\}', content, re.DOTALL)
            for cat_name, cat_content in cat_blocks:
                keys = re.findall(r'"([^"]+)"\s*:', cat_content)
                dupes = [k for k in set(keys) if keys.count(k) > 1]
                if dupes:
                    print(f"âš ï¸  [{json_file.name}] '{cat_name}' ì¹´í…Œê³ ë¦¬ ë‚´ ì¤‘ë³µ í‚¤: {', '.join(dupes)}")
                    dupe_count += len(dupes)
                    
        except Exception as e:
            print(f"âŒ [{json_file.name}] JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return False
            
    print(f"ì´ ë²ˆì—­ í•­ëª©: {total_entries}ê°œ")
    if empty_count: print(f"âš ï¸  ë¹ˆ ë²ˆì—­ í•­ëª©: {empty_count}ê°œ")
    if dupe_count: print(f"âš ï¸  ì¤‘ë³µ í‚¤ ë°œê²¬: {dupe_count}ê°œ")
    
    if not empty_count and not dupe_count: print("âœ… ë²ˆì—­ ë°ì´í„° ë¬´ê²°ì„± í™•ì¸")
    return dupe_count == 0

# ============================================================================
# 3. ë©”íƒ€ë°ì´í„° ë° ì¸ë±ìŠ¤ ìƒì„±
# ============================================================================

def build_project_references():
    """í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„°(json) ë° ì¸ë±ìŠ¤(md) ìƒì„±"""
    print("\n" + "=" * 80)
    print("ğŸ”§ í”„ë¡œì íŠ¸ ë ˆí¼ëŸ°ìŠ¤ ìƒì„± (Metadata & Index)")
    print("=" * 80)
    
    db = {
        "generated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "scripts": {}, "tools": {}, "docs": {}, "localization": {}
    }
    
    # 1. Scripts ìŠ¤ìº”
    for cs_file in SCRIPTS_DIR.rglob("*.cs"):
        if "_Legacy" in str(cs_file): continue
        with open(cs_file, 'r', encoding='utf-8') as f: content = f.read()
        
        rel_path = str(cs_file.relative_to(PROJECT_ROOT))
        
        # íŒŒì¼ í—¤ë” ì •ë³´ ì¶”ì¶œ
        classification = "N/A"
        role = "N/A"
        class_match = re.search(r'\* ë¶„ë¥˜:\s*\[([^\]]+)\]', content)
        role_match = re.search(r'\* ì—­í• :\s*([^\n\*]+)', content)
        if class_match: classification = class_match.group(1).strip()
        if role_match: role = role_match.group(1).strip()

        ns_match = re.search(r'namespace\s+([\w\.]+)', content)
        
        db["scripts"][rel_path] = {
            "classification": classification,
            "role": role,
            "namespace": ns_match.group(1) if ns_match else None,
            "classes": re.findall(r'(?:public|internal)\s+(?:static\s+)?class\s+(\w+)', content),
            "methods": [
                {"name": m[1], "return": m[0], "params": m[2].strip() or ""}
                for m in re.findall(r'public\s+(?:static\s+)?([\w\[\]<>]+)\s+(\w+)\s*\(([^)]*)\)', content)
            ]
        }

    # 2. ë„êµ¬/ë¬¸ì„œ/ë¡œì»¬ë¼ì´ì œì´ì…˜ ìŠ¤ìº”
    for path in TOOLS_DIR.iterdir():
        if path.is_file() and path.suffix == ".py":
            db["tools"][path.name] = {"type": "script", "size": path.stat().st_size}
        elif path.is_dir() and not path.name.startswith(('.', '_')):
            db["tools"][path.name] = {"type": "tool_folder"}
    for md_file in DOCS_DIR.glob("*.md"):
        db["docs"][md_file.name] = {"modified": datetime.fromtimestamp(md_file.stat().st_mtime).strftime("%Y-%m-%d")}
    for json_file in LOCALIZATION_DIR.glob("*.json"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)
            db["localization"][json_file.name] = {
                "categories": list(data.keys()),
                "entries": sum(len(v) if isinstance(v, dict) else 0 for v in data.values())
            }
        except: pass

    # íŒŒì¼ ì €ì¥
    with open(TOOLS_DIR / "project_metadata.json", 'w', encoding='utf-8') as f:
        json.dump(db, f, indent=2, ensure_ascii=False)
    
    # 3. 01_CORE_PROJECT_INDEX.md ìƒì„±
    lines = ["# ğŸ“š í”„ë¡œì íŠ¸ ì™„ì „ ì¸ë±ìŠ¤ (ìë™ ìƒì„±)", f"\n**ìƒì„±**: {db['generated']}\n", "ì´ ë¬¸ì„œëŠ” í”„ë¡œì íŠ¸ì˜ ëª¨ë“  íŒŒì¼ê³¼ ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. **ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ë§Œë“¤ê¸° ì „, ë°˜ë“œì‹œ ì—¬ê¸°ì„œ ê¸°ì¡´ ë©”ì„œë“œë¥¼ ê²€ìƒ‰í•˜ì‹­ì‹œì˜¤.**\n", "=" * 80]
    
    # ë¶„ë¥˜ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì¶œë ¥í•˜ë©´ ë” ì²´ê³„ì ì„
    by_class = {}
    for key, meta in db["scripts"].items():
        cls = meta["classification"]
        if cls not in by_class: by_class[cls] = []
        by_class[cls].append((key, meta))
        
    for cls in sorted(by_class.keys()):
        lines.append(f"\n## ğŸ“‚ [{cls}]")
        for key, meta in sorted(by_class[cls]):
            lines.append(f"\n### `{key}`")
            lines.append(f"- **ì—­í• **: {meta['role']}")
            if meta["namespace"]: lines.append(f"- **Namespace**: `{meta['namespace']}`")
            if meta["methods"]:
                lines.append("- **ê³µê°œ ë©”ì„œë“œ (Public Methods)**:")
                lines.append("  ```csharp")
                for m in meta["methods"][:15]: # ë©”ì„œë“œ ìˆ˜ 15ê°œë¡œ ìƒí–¥
                    lines.append(f"  {m['return']} {m['name']}({m['params']})")
                if len(meta["methods"]) > 15:
                    lines.append(f"  ... ì™¸ {len(meta['methods'])-15}ê°œ")
                lines.append("  ```")
    
    with open(DOCS_DIR / "01_CORE_PROJECT_INDEX.md", 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))
        
    # 4. 02_CORE_QUICK_REFERENCE.md ìƒì„±
    q_lines = ["# ğŸš€ í”„ë¡œì íŠ¸ ë¹ ë¥¸ ì°¸ì¡° (ìë™ ìƒì„±)", f"\n**ìƒì„±**: {db['generated']}\n", "## â­ í•µì‹¬ ê²½ë¡œ"]
    q_lines.append("```\nScripts/00_Core/00_00_01_TranslationEngine.cs  â†’ í•µì‹¬ ì—”ì§„\nScripts/00_Core/00_00_03_LocalizationManager.cs â†’ ë°ì´í„° ê´€ë¦¬\nLOCALIZATION/glossary_*.json              â†’ ìš©ì–´ì§‘ ë°ì´í„°\n```")
    
    q_lines.append("\n## ğŸ“š ìš©ì–´ì§‘ í˜„í™©")
    for k, v in sorted(db["localization"].items()):
        q_lines.append(f"- `{k}`: {v['entries']}ê°œ í•­ëª©")

    q_lines.append("\n## â›” ì ˆëŒ€ ê¸ˆì§€ (DO NOT)")
    q_lines.append("```")
    q_lines.append("âŒ _Legacy/ í´ë”ì˜ ì½”ë“œ ì‚¬ìš©")
    q_lines.append("âŒ TranslationEngine ë¡œì§ ì¤‘ë³µ êµ¬í˜„")
    q_lines.append("âŒ ìƒ‰ìƒ íƒœê·¸/í”„ë¦¬í”½ìŠ¤ ìˆ˜ë™ ì²˜ë¦¬")
    q_lines.append("âŒ project_tool.py ê²€ì¦ ì—†ì´ ë°°í¬")
    q_lines.append("```")

    q_lines.append("\n## âœ… ì‘ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸")
    q_lines.append("```")
    q_lines.append("1. 01_CORE_PROJECT_INDEX.mdì—ì„œ ê¸°ì¡´ í•¨ìˆ˜ í™•ì¸")
    q_lines.append("2. Scripts/ ë‚´ë¶€ ë¡œì§ ìˆ˜ì •")
    q_lines.append("3. python3 tools/project_tool.py ë¡œ ê²€ì¦")
    q_lines.append("4. ./tools/deploy-mods.sh ë¡œ ê²Œì„ ì ìš©")
    q_lines.append("```")
        
    with open(DOCS_DIR / "02_CORE_QUICK_REFERENCE.md", 'w', encoding='utf-8') as f:
        f.write("\n".join(q_lines))

    print(f"âœ… ë ˆí¼ëŸ°ìŠ¤ ê°€ì´ë“œ ê°±ì‹ : Docs/02_CORE_QUICK_REFERENCE.md")

    print(f"âœ… ë©”íƒ€ë°ì´í„° ë° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (Docs 01, 02 ê°±ì‹ )")

# ============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# ============================================================================

def main():
    print("\n" + "ğŸš€" * 40)
    print("  Qud í•œê¸€í™” í”„ë¡œì íŠ¸ í†µí•© ë„êµ¬ í™˜ê²½ ê²€ì¦ ì‹œì‘")
    print("ğŸš€" * 40)
    
    results = [
        verify_code(),
        verify_localization()
    ]
    
    build_project_references()
    
    print("\n" + "=" * 80)
    if all(results):
        print("âœ¨ ëª¨ë“  ê²€ì¦ ë° ìƒì„± ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸  ì¼ë¶€ ê²€ì¦ ë‹¨ê³„ì—ì„œ ì£¼ì˜ì‚¬í•­ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    print("=" * 80 + "\n")

if __name__ == "__main__":
    main()
