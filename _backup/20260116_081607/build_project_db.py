#!/usr/bin/env python3
"""
í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±ê¸°
- ëª¨ë“  íŒŒì¼ì˜ ì‹œê·¸ë‹ˆì²˜ ì¶”ì¶œ
- JSON ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì €ì¥
- íŒŒì¼ ì—´ì§€ ì•Šê³  ë©”ì„œë“œ/í´ë˜ìŠ¤ í™•ì¸ ê°€ëŠ¥
"""

import os
import re
import json
from pathlib import Path
from datetime import datetime

PROJECT_ROOT = Path("/Users/ben/Desktop/qud_korean")

def extract_cs_metadata(file_path):
    """C# íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    metadata = {
        "type": "csharp",
        "path": str(file_path.relative_to(PROJECT_ROOT)),
        "size": len(content),
        "lines": content.count('\n'),
        "modified": datetime.fromtimestamp(file_path.stat().st_mtime).strftime("%Y-%m-%d %H:%M"),
        "namespace": None,
        "classes": [],
        "methods": [],
        "using": []
    }
    
    # Namespace ì¶”ì¶œ
    ns_match = re.search(r'namespace\s+([\w\.]+)', content)
    if ns_match:
        metadata["namespace"] = ns_match.group(1)
    
    # Using ë¬¸ ì¶”ì¶œ
    metadata["using"] = re.findall(r'using\s+([\w\.]+);', content)
    
    # í´ë˜ìŠ¤ ì¶”ì¶œ (public/internalë§Œ)
    class_pattern = r'(?:public|internal)\s+(?:static\s+)?(?:partial\s+)?class\s+(\w+)'
    metadata["classes"] = re.findall(class_pattern, content)
    
    # ë©”ì„œë“œ ì¶”ì¶œ (publicë§Œ, ì‹œê·¸ë‹ˆì²˜ í¬í•¨)
    method_pattern = r'public\s+(?:static\s+)?(?:async\s+)?(\w+(?:<[^>]+>)?)\s+(\w+)\s*\(([^)]*)\)'
    methods = re.findall(method_pattern, content)
    metadata["methods"] = [
        {
            "return_type": m[0],
            "name": m[1],
            "params": m[2].strip() if m[2].strip() else "void"
        }
        for m in methods
    ]
    
    return metadata

def extract_py_metadata(file_path):
    """Python íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    metadata = {
        "type": "python",
        "path": str(file_path.relative_to(PROJECT_ROOT)),
        "size": len(content),
        "lines": content.count('\n'),
        "modified": datetime.fromtimestamp(file_path.stat().st_mtime).strftime("%Y-%m-%d %H:%M"),
        "functions": [],
        "description": None
    }
    
    # Docstring ì¶”ì¶œ
    doc_match = re.search(r'"""([^"]+)"""', content)
    if doc_match:
        metadata["description"] = doc_match.group(1).strip().split('\n')[0]
    
    # í•¨ìˆ˜ ì¶”ì¶œ
    func_pattern = r'def\s+(\w+)\s*\(([^)]*)\)'
    functions = re.findall(func_pattern, content)
    metadata["functions"] = [
        {
            "name": f[0],
            "params": f[1].strip() if f[1].strip() else "void"
        }
        for f in functions
    ]
    
    return metadata

def extract_md_metadata(file_path):
    """Markdown íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    metadata = {
        "type": "markdown",
        "path": str(file_path.relative_to(PROJECT_ROOT)),
        "size": len(content),
        "lines": content.count('\n'),
        "modified": datetime.fromtimestamp(file_path.stat().st_mtime).strftime("%Y-%m-%d %H:%M"),
        "title": None,
        "headers": []
    }
    
    # ì œëª© ì¶”ì¶œ (ì²« ë²ˆì§¸ # í—¤ë”)
    title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
    if title_match:
        metadata["title"] = title_match.group(1).strip()
    
    # ëª¨ë“  í—¤ë” ì¶”ì¶œ
    metadata["headers"] = re.findall(r'^#{1,3}\s+(.+)$', content, re.MULTILINE)
    
    return metadata

def extract_json_metadata(file_path):
    """JSON íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        metadata = {
            "type": "json",
            "path": str(file_path.relative_to(PROJECT_ROOT)),
            "size": file_path.stat().st_size,
            "modified": datetime.fromtimestamp(file_path.stat().st_mtime).strftime("%Y-%m-%d %H:%M"),
            "categories": list(data.keys()) if isinstance(data, dict) else [],
            "total_entries": sum(len(v) if isinstance(v, dict) else 0 for v in data.values()) if isinstance(data, dict) else 0
        }
        return metadata
    except:
        return None

def build_database():
    """ì „ì²´ í”„ë¡œì íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•"""
    db = {
        "generated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "scripts": {},
        "tools": {},
        "docs": {},
        "localization": {}
    }
    
    print("ğŸ” í”„ë¡œì íŠ¸ ìŠ¤ìº” ì¤‘...")
    
    # Scripts í´ë”
    scripts_dir = PROJECT_ROOT / "Scripts"
    if scripts_dir.exists():
        for cs_file in scripts_dir.rglob("*.cs"):
            if "_Legacy" in str(cs_file):
                continue  # ë ˆê±°ì‹œ ì œì™¸
            key = str(cs_file.relative_to(PROJECT_ROOT))
            db["scripts"][key] = extract_cs_metadata(cs_file)
    
    # Python ë„êµ¬
    for py_file in PROJECT_ROOT.glob("*.py"):
        key = py_file.name
        db["tools"][key] = extract_py_metadata(py_file)
    
    # ë¬¸ì„œ
    for md_file in PROJECT_ROOT.glob("*.md"):
        if "_Docs_Archive" in str(md_file):
            continue  # ì•„ì¹´ì´ë¸Œ ì œì™¸
        key = md_file.name
        db["docs"][key] = extract_md_metadata(md_file)
    
    # Localization
    loc_dir = PROJECT_ROOT / "LOCALIZATION"
    if loc_dir.exists():
        for json_file in loc_dir.glob("*.json"):
            key = json_file.name
            meta = extract_json_metadata(json_file)
            if meta:
                db["localization"][key] = meta
    
    return db

def generate_human_readable_index(db):
    """ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ì¸ë±ìŠ¤ ìƒì„±"""
    lines = []
    lines.append("# ğŸ“š í”„ë¡œì íŠ¸ ì™„ì „ ì¸ë±ìŠ¤ (ìë™ ìƒì„±)")
    lines.append(f"\n**ìƒì„±**: {db['generated']}")
    lines.append("\n" + "=" * 80)
    
    # í•µì‹¬ Scripts
    lines.append("\n## ğŸ”§ Scripts (í•µì‹¬ ì½”ë“œ)")
    lines.append("\n### TranslationEngine ë° Core")
    
    core_files = [k for k in db["scripts"].keys() if "00_Core" in k]
    for key in sorted(core_files):
        meta = db["scripts"][key]
        lines.append(f"\n#### `{key}`")
        if meta["classes"]:
            lines.append(f"- **í´ë˜ìŠ¤**: {', '.join(meta['classes'])}")
        if meta["methods"]:
            lines.append(f"- **ì£¼ìš” ë©”ì„œë“œ**:")
            for m in meta["methods"][:5]:  # ìµœëŒ€ 5ê°œ
                lines.append(f"  - `{m['return_type']} {m['name']}({m['params']})`")
    
    lines.append("\n### Utils")
    utils_files = [k for k in db["scripts"].keys() if "99_Utils" in k]
    for key in sorted(utils_files):
        meta = db["scripts"][key]
        lines.append(f"\n#### `{key}`")
        if meta["classes"]:
            lines.append(f"- **í´ë˜ìŠ¤**: {', '.join(meta['classes'])}")
        if meta["methods"]:
            lines.append(f"- **ë©”ì„œë“œ**: {', '.join([m['name'] for m in meta['methods'][:5]])}")
    
    # Python ë„êµ¬
    lines.append("\n## ğŸ Python ë„êµ¬")
    for key in sorted(db["tools"].keys()):
        meta = db["tools"][key]
        lines.append(f"\n### `{key}`")
        if meta["description"]:
            lines.append(f"- {meta['description']}")
        if meta["functions"]:
            lines.append(f"- **í•¨ìˆ˜**: {', '.join([f['name'] for f in meta['functions'][:5]])}")
    
    # ë¬¸ì„œ
    lines.append("\n## ğŸ“– ë¬¸ì„œ")
    priority_docs = ["AI_START_HERE.md", "QUICK_REFERENCE.md", "CODEBASE_MAP.md", "WORKFLOW.md"]
    for doc in priority_docs:
        if doc in db["docs"]:
            meta = db["docs"][doc]
            lines.append(f"\n### â­ `{doc}`")
            if meta["title"]:
                lines.append(f"- **ì œëª©**: {meta['title']}")
            lines.append(f"- **ìˆ˜ì •**: {meta['modified']}")
    
    # Glossary
    lines.append("\n## ğŸ“š Glossary íŒŒì¼")
    for key in sorted(db["localization"].keys()):
        meta = db["localization"][key]
        lines.append(f"\n### `{key}`")
        lines.append(f"- **í•­ëª© ìˆ˜**: {meta['total_entries']}")
        lines.append(f"- **ì¹´í…Œê³ ë¦¬**: {', '.join(meta['categories'])}")
    
    lines.append("\n" + "=" * 80)
    lines.append("\n**ì´ íŒŒì¼ì€ ìë™ ìƒì„±ë©ë‹ˆë‹¤.**")
    lines.append("\nì¬ìƒì„±: `python3 build_project_db.py`")
    
    return "\n".join(lines)

def main():
    print("=" * 80)
    print("ğŸš€ í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±")
    print("=" * 80 + "\n")
    
    # ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
    db = build_database()
    
    # JSON ì €ì¥
    db_file = PROJECT_ROOT / "project_metadata.json"
    with open(db_file, 'w', encoding='utf-8') as f:
        json.dump(db, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… JSON ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥: {db_file}")
    print(f"   - Scripts: {len(db['scripts'])}ê°œ")
    print(f"   - Tools: {len(db['tools'])}ê°œ")
    print(f"   - Docs: {len(db['docs'])}ê°œ")
    print(f"   - Localization: {len(db['localization'])}ê°œ")
    
    # ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ì¸ë±ìŠ¤ ìƒì„±
    index_content = generate_human_readable_index(db)
    index_file = PROJECT_ROOT / "PROJECT_INDEX.md"
    with open(index_file, 'w', encoding='utf-8') as f:
        f.write(index_content)
    
    print(f"\nâœ… ì¸ë±ìŠ¤ íŒŒì¼ ìƒì„±: {index_file}")
    print(f"   í¬ê¸°: {len(index_content)} bytes")
    
    print("\n" + "=" * 80)
    print("âœ… ì™„ë£Œ!")
    print("=" * 80)
    print("\nì‚¬ìš©ë²•:")
    print("  1. cat PROJECT_INDEX.md  # ì‚¬ëŒì´ ì½ê¸°")
    print("  2. cat project_metadata.json  # í”„ë¡œê·¸ë¨ì´ ì½ê¸°")

if __name__ == "__main__":
    main()
